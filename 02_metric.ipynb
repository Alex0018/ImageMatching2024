{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.imc24 import score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiply translation vector by a constant\n",
    "\n",
    "Doesn't change the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** transp_obj_glass_cup ***\n",
      "\n",
      "mAA: 1.0\n",
      "\n",
      "*** dioscuri ***\n",
      "\n",
      "mAA: 1.0\n",
      "\n",
      "*** church ***\n",
      "\n",
      "mAA: 1.0\n",
      "\n",
      "*** multi-temporal-temple-baalshamin ***\n",
      "\n",
      "mAA: 0.9783\n",
      "\n",
      "*** transp_obj_glass_cylinder ***\n",
      "\n",
      "mAA: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9956521739130434"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub = pd.read_csv('data/train/train_labels.csv') \\\n",
    "            .query('(dataset != \"pond\") & (dataset != \"lizard\")') \\\n",
    "            .sample(n=200)\n",
    "df_sub = df_sub.rename(columns={'image_name': 'image_path'})\n",
    "\n",
    "\n",
    "df_preds = df_sub.copy()\n",
    "translation_cols = ['tx', 'ty', 'tz']\n",
    "df_preds[translation_cols] = df_preds['translation_vector'].str.split(';', expand=True).astype(float)\n",
    "\n",
    "rotations_cols = ['r' + ''.join([str(i),str(j)]) for i in range(3) for j in range(3)]\n",
    "df_preds[rotations_cols] = df_preds['rotation_matrix'].str.split(';', expand=True).astype(float)\n",
    "\n",
    "df_preds[translation_cols] *= 2\n",
    "\n",
    "df_preds['rotation_matrix'] = df_preds[rotations_cols].apply(lambda row: \n",
    "                 np.array2string(row.values, separator=';') \\\n",
    "                     .replace(' ', '') \\\n",
    "                     .replace('\\n', '')[1:-1], \n",
    "                 axis=1)\n",
    "df_preds['translation_vector'] = df_preds[translation_cols].apply(lambda row: \n",
    "                 np.array2string(row.values, separator=';') \\\n",
    "                     .replace(' ', '') \\\n",
    "                     .replace('\\n', '')[1:-1], \n",
    "                 axis=1)\n",
    "\n",
    "score(df_sub, df_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add noise to ground truth\n",
    "\n",
    "Score decreases rapidly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotation with additive noise 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** transp_obj_glass_cup ***\n",
      "\n",
      "mAA: 0.697\n",
      "\n",
      "*** dioscuri ***\n",
      "\n",
      "mAA: 0.3659\n",
      "\n",
      "*** church ***\n",
      "\n",
      "mAA: 0.1583\n",
      "\n",
      "*** multi-temporal-temple-baalshamin ***\n",
      "\n",
      "mAA: 0.2982\n",
      "\n",
      "*** transp_obj_glass_cylinder ***\n",
      "\n",
      "mAA: 0.7105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4460033978226198"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub = pd.read_csv('data/train/train_labels.csv') \\\n",
    "            .query('(dataset != \"pond\") & (dataset != \"lizard\")') \\\n",
    "            .sample(n=200)\n",
    "df_sub = df_sub.rename(columns={'image_name': 'image_path'})\n",
    "\n",
    "df_preds = df_sub.copy()\n",
    "translation_cols = ['tx', 'ty', 'tz']\n",
    "df_preds[translation_cols] = df_preds['translation_vector'].str.split(';', expand=True).astype(float)\n",
    "\n",
    "rotations_cols = ['r' + ''.join([str(i),str(j)]) for i in range(3) for j in range(3)]\n",
    "df_preds[rotations_cols] = df_preds['rotation_matrix'].str.split(';', expand=True).astype(float)\n",
    "\n",
    "noise_level = 0.02\n",
    "df_preds[rotations_cols] += noise_level*2*(np.random.rand(*df_preds[rotations_cols].shape) - 0.5)\n",
    "\n",
    "df_preds['rotation_matrix'] = df_preds[rotations_cols].apply(lambda row: \n",
    "                 np.array2string(row.values, separator=';') \\\n",
    "                     .replace(' ', '') \\\n",
    "                     .replace('\\n', '')[1:-1], \n",
    "                 axis=1)\n",
    "df_preds['translation_vector'] = df_preds[translation_cols].apply(lambda row: \n",
    "                 np.array2string(row.values, separator=';') \\\n",
    "                     .replace(' ', '') \\\n",
    "                     .replace('\\n', '')[1:-1], \n",
    "                 axis=1)\n",
    "\n",
    "score(df_sub, df_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### translation with additive noise 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** transp_obj_glass_cup ***\n",
      "\n",
      "mAA: 0.8542\n",
      "\n",
      "*** church ***\n",
      "\n",
      "mAA: 0.2114\n",
      "\n",
      "*** dioscuri ***\n",
      "\n",
      "mAA: 0.0946\n",
      "\n",
      "*** multi-temporal-temple-baalshamin ***\n",
      "\n",
      "mAA: 0.1126\n",
      "\n",
      "*** transp_obj_glass_cylinder ***\n",
      "\n",
      "mAA: 0.8417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4228966653220384"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub = pd.read_csv('data/train/train_labels.csv') \\\n",
    "            .query('(dataset != \"pond\") & (dataset != \"lizard\")') \\\n",
    "            .sample(n=200)\n",
    "df_sub = df_sub.rename(columns={'image_name': 'image_path'})\n",
    "\n",
    "df_preds = df_sub.copy()\n",
    "translation_cols = ['tx', 'ty', 'tz']\n",
    "df_preds[translation_cols] = df_preds['translation_vector'].str.split(';', expand=True).astype(float)\n",
    "\n",
    "rotations_cols = ['r' + ''.join([str(i),str(j)]) for i in range(3) for j in range(3)]\n",
    "df_preds[rotations_cols] = df_preds['rotation_matrix'].str.split(';', expand=True).astype(float)\n",
    "\n",
    "# normalize translation vectors\n",
    "df_preds['translation_norm'] = np.sqrt((df_preds[translation_cols]**2).sum(axis=1))\n",
    "df_preds['translation_norm_max'] = df_preds.groupby('dataset')['translation_norm'].transform('max')\n",
    "for col in translation_cols:\n",
    "    df_preds[col] /= df_preds['translation_norm_max']\n",
    "\n",
    "noise_level = 0.01\n",
    "df_preds[translation_cols] += noise_level*2*(np.random.rand(*df_preds[translation_cols].shape) - 0.5)\n",
    "\n",
    "df_preds['rotation_matrix'] = df_preds[rotations_cols].apply(lambda row: \n",
    "                 np.array2string(row.values, separator=';') \\\n",
    "                     .replace(' ', '') \\\n",
    "                     .replace('\\n', '')[1:-1], \n",
    "                 axis=1)\n",
    "df_preds['translation_vector'] = df_preds[translation_cols].apply(lambda row: \n",
    "                 np.array2string(row.values, separator=';') \\\n",
    "                     .replace(' ', '') \\\n",
    "                     .replace('\\n', '')[1:-1], \n",
    "                 axis=1)\n",
    "\n",
    "score(df_sub, df_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean of different predictions\n",
    "\n",
    "The score decreases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Prediction 1\n",
      "\n",
      "*** multi-temporal-temple-baalshamin ***\n",
      "\n",
      "mAA: 0.241\n",
      "\n",
      "*** church ***\n",
      "\n",
      "mAA: 0.2835\n",
      "\n",
      "*** dioscuri ***\n",
      "\n",
      "mAA: 0.4055\n",
      "Mean score: 0.30999579147159\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prediction 2\n",
      "\n",
      "*** multi-temporal-temple-baalshamin ***\n",
      "\n",
      "mAA: 0.2205\n",
      "\n",
      "*** church ***\n",
      "\n",
      "mAA: 0.285\n",
      "\n",
      "*** dioscuri ***\n",
      "\n",
      "mAA: 0.3433\n",
      "Mean score: 0.28294771052477846\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Score(prediction1, prediction2)\n",
      "\n",
      "*** multi-temporal-temple-baalshamin ***\n",
      "\n",
      "mAA: 0.7941\n",
      "\n",
      "*** church ***\n",
      "\n",
      "mAA: 0.8651\n",
      "\n",
      "*** dioscuri ***\n",
      "\n",
      "mAA: 0.7833\n",
      "Mean score: 0.8141767818238406\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Average of predictions\n",
      "\n",
      "*** multi-temporal-temple-baalshamin ***\n",
      "\n",
      "mAA: 0.2308\n",
      "\n",
      "*** church ***\n",
      "\n",
      "mAA: 0.2819\n",
      "\n",
      "*** dioscuri ***\n",
      "\n",
      "mAA: 0.3682\n",
      "Mean score: 0.29361996630792836\n"
     ]
    }
   ],
   "source": [
    "datasets = ['dioscuri', 'church', 'multi-temporal-temple-baalshamin']\n",
    "\n",
    "dfs = []\n",
    "for dataset in datasets:\n",
    "    df_sub = pd.read_csv('data/train/train_labels.csv').query(f'dataset == \"{dataset}\"')\n",
    "    df_sub = df_sub.rename(columns={'image_name': 'image_path'})\n",
    "    df_sub['image_path'] = df_sub.apply(lambda row: f'data\\\\train\\\\{row[\"dataset\"]}\\\\images\\\\' + row['image_path'], axis=1)\n",
    "    dfs.append(df_sub)\n",
    "df_sub = pd.concat(dfs)\n",
    "\n",
    "dfs_1, dfs_2 = [], []\n",
    "for dataset in datasets:\n",
    "    dfs_1.append(pd.read_csv(f'data/train/result_{dataset}_pairs0.1x30_disk768_LightGlue_matchesT0.3.csv'))\n",
    "    dfs_2.append(pd.read_csv(f'data/train/result_{dataset}_pairs0.3x5_aliked1024_LightGlue_matchesT0.01.csv'))\n",
    "\n",
    "df_1 = pd.concat(dfs_1)\n",
    "df_2 = pd.concat(dfs_2)\n",
    "\n",
    "df_preds = df_1.copy()\n",
    "\n",
    "for df in [df_1, df_2]:\n",
    "    translation_cols = ['tx', 'ty', 'tz']\n",
    "    df[translation_cols] = df_preds['translation_vector'].str.split(';', expand=True).astype(float)\n",
    "\n",
    "    rotations_cols = ['r' + ''.join([str(i),str(j)]) for i in range(3) for j in range(3)]\n",
    "    df[rotations_cols] = df['rotation_matrix'].str.split(';', expand=True).astype(float)\n",
    "\n",
    "\n",
    "df_preds[translation_cols] = df_1[translation_cols] + df_2[translation_cols]\n",
    "df_preds[rotations_cols] = 0.5*(df_1[rotations_cols] + df_2[rotations_cols])\n",
    "\n",
    "\n",
    "df_preds['rotation_matrix'] = df_preds[rotations_cols].apply(lambda row: \n",
    "                 np.array2string(row.values, separator=';') \\\n",
    "                     .replace(' ', '') \\\n",
    "                     .replace('\\n', '')[1:-1], \n",
    "                 axis=1)\n",
    "df_preds['translation_vector'] = df_preds[translation_cols].apply(lambda row: \n",
    "                 np.array2string(row.values, separator=';') \\\n",
    "                     .replace(' ', '') \\\n",
    "                     .replace('\\n', '')[1:-1], \n",
    "                 axis=1)\n",
    "\n",
    "print('-'*100)\n",
    "print('Prediction 1')\n",
    "print('Mean score:', score(df_sub, df_1))\n",
    "\n",
    "print('-'*100)\n",
    "print('Prediction 2')\n",
    "print('Mean score:', score(df_sub, df_2))\n",
    "\n",
    "print('-'*100)\n",
    "print('Score(prediction1, prediction2)')\n",
    "print('Mean score:', score(df_1.dropna(), df_2.dropna()))\n",
    "\n",
    "print('-'*100)\n",
    "print('Average of predictions')\n",
    "print('Mean score:', score(df_sub, df_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
